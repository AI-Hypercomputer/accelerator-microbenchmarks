benchmarks:
- benchmark_name: "naive_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: true}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
- benchmark_name: "pallas_flash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
- benchmark_name: "splash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
- benchmark_name: "flax_nnx_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
- benchmark_name: "flax_linen_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
- benchmark_name: "keras_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 4, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  trace_dir: "/tmp/microbenchmarks/attention"
  csv_path: "/tmp/microbenchmarks/attention"
  xlml_metrics_dir: "/tmp/microbenchmarks/attention"
